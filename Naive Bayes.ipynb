{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_text(text):\n",
    "    new_text = \"\"\n",
    "    html_tag = False\n",
    "    for c in text:\n",
    "        if(c == \"<\"):\n",
    "            html_tag = True\n",
    "            continue\n",
    "        elif(c == \">\"):\n",
    "            html_tag = False\n",
    "            continue\n",
    "        if(html_tag == False):\n",
    "            if(c not in punctuation):\n",
    "                new_text += c\n",
    "            else:\n",
    "                new_text += \" \"\n",
    "    return new_text.lower()\n",
    "\n",
    "def email_parser():\n",
    "    files = glob.glob(\"DATA\\*.eml\")\n",
    "    emails_set = dict()\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            try:\n",
    "                text = msg.get_body(preferencelist=('plain')).get_content()\n",
    "            except:\n",
    "                text.encode('utf-32', 'surrogateescape').decode('utf-32') \n",
    "            new_text = flat_text(text)    \n",
    "            words_set = dict()\n",
    "            email_words = re.split(\" |\\n|\\t\", new_text)\n",
    "            for word in email_words:\n",
    "                try:\n",
    "                    words_set[word] += 1\n",
    "                except:\n",
    "                    words_set[word] = 1\n",
    "            emails_set[file.split(\"\\\\\")[1]] = words_set\n",
    "    return emails_set        \n",
    "\n",
    "def label_parser():\n",
    "    file = open(\"SPAMTrain.label\", \"r\")\n",
    "    labels_set = dict()\n",
    "    if file.mode == 'r':\n",
    "        for line in file.readlines():\n",
    "            vec = line.split(\" \")\n",
    "            labels_set[vec[1].replace('\\n', '')] = vec[0]\n",
    "    return labels_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = email_parser()\n",
    "labels = label_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x,y, train_size = 0.8):\n",
    "    perm = np.random.permutation(list(x.keys()))\n",
    "    dict_size = len(x)\n",
    "    x_train = dict()\n",
    "    y_train = dict()\n",
    "    x_test = dict()\n",
    "    y_test = dict()\n",
    "    i = 0\n",
    "    index = len(x)*train_size\n",
    "    for k in perm:\n",
    "        if (i < index):\n",
    "            x_train[k] = x[k] \n",
    "            y_train[k] = y[k]\n",
    "        else:\n",
    "            x_test[k] = x[k] \n",
    "            y_test[k] = y[k]\n",
    "        i += 1\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_train, label_train, email_test, label_test = train_test_split(emails, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    p_spams = dict() #P(word|spam)\n",
    "    p_hams = dict() #P(word|ham)\n",
    "    p_spam = 0 #P(spam)\n",
    "    p_ham = 0  #P(ham)\n",
    "    n_spam = 0 #Qtd total de palavras em spam\n",
    "    n_ham = 0 #Qtd total de palavras em ham\n",
    "    dict_size = 0 #Qtd de palavras distintas nos emails\n",
    "    \n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "        \n",
    "    def set_k(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def divide(self, emails, labels):\n",
    "        spams = 0\n",
    "        hams = 0\n",
    "        words_spam = dict()\n",
    "        words_ham = dict()\n",
    "        words = dict()\n",
    "      \n",
    "        for item in emails:\n",
    "            if(int(labels[item]) == 0):\n",
    "                spams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_spam[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_spam[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    self.n_spam  += emails[item][word]\n",
    "            else:\n",
    "                hams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_ham[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_ham[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    self.n_ham += emails[item][word]\n",
    "                    \n",
    "        return words, words_spam, words_ham, spams, hams\n",
    "    \n",
    "    def fit(self, emails, labels):\n",
    "        words, words_spam, words_ham, spams, hams = self.divide(emails, labels)\n",
    "        self.p_spam = (spams + self.k)/(spams + hams + 2*self.k) #P(spam)\n",
    "        self.p_ham = (hams + self.k)/(spams + hams + 2*self.k) #P(ham)\n",
    "        self.dict_size = len(words)\n",
    "        for item in words:\n",
    "            try:\n",
    "                self.p_spams[item] = (words_spam[item] + self.k)/(self.n_spam + (self.k*self.dict_size))\n",
    "            except:\n",
    "                self.p_spams[item] = (self.k)/(self.n_spam + (self.k*self.dict_size))\n",
    "            try:\n",
    "                self.p_hams[item] = (words_ham[item] + self.k)/(self.n_ham + (self.k*self.dict_size))\n",
    "            except:\n",
    "                self.p_hams[item] = (self.k)/(self.n_ham + (self.k*self.dict_size))\n",
    "\n",
    "    def predict(self, emails):\n",
    "        labels = list()\n",
    "        for item in emails:\n",
    "            p_bespam = math.log(self.p_spam)\n",
    "            p_beham = math.log(self.p_ham)\n",
    "            for word in emails[item]:\n",
    "                try:\n",
    "                    p_bespam += math.log(self.p_spams[word])\n",
    "                except:\n",
    "                    p_bespam += math.log((self.k)/(self.n_spam + (self.k*self.dict_size)))\n",
    "                try:\n",
    "                    p_beham += math.log(self.p_hams[word]) \n",
    "                except:\n",
    "                    p_beham += math.log((self.k)/(self.n_ham + (self.k*self.dict_size)))\n",
    "            labels.append(1 if p_bespam<p_beham else 0)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.fit(emails_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = nb.predict(emails_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, labels_val):\n",
    "    num = 0\n",
    "    total = 0\n",
    "    for i in labels_val:\n",
    "        if(prediction[total] == int(labels_val[i])):\n",
    "            num += 1\n",
    "        total += 1\n",
    "    return num/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid_search_cv:\n",
    "    self.x = dict()\n",
    "    self.y = dict()\n",
    "    def __init__(self, clf, params, cv = 10):\n",
    "        self.clf = clf\n",
    "        self.params = params\n",
    "        self.cv = cv\n",
    "    def kfold(k = 10):\n",
    "        size_part = len(self.x)//k\n",
    "        perm = np.random.permutation(list(x.keys()))\n",
    "        \n",
    "        #toda partição tem que ser teste uma vez\n",
    "        #pra cada partiçao eu pego o slice da ista pra escolher o train e test\n",
    "        #chamar o classificador\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        #chamar o kfold pra cada param\n",
    "        #treinar o classificador de novo com o conjunto todo\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
