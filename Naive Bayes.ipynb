{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_text(text):\n",
    "    new_text = \"\"\n",
    "    html_tag = False\n",
    "    for c in text:\n",
    "        if(c == \"<\"):\n",
    "            html_tag = True\n",
    "            continue\n",
    "        elif(c == \">\"):\n",
    "            html_tag = False\n",
    "            continue\n",
    "        if(html_tag == False):\n",
    "            if(c not in punctuation):\n",
    "                new_text += c\n",
    "            else:\n",
    "                new_text += \" \"\n",
    "    return new_text.lower()\n",
    "\n",
    "def email_parser():\n",
    "    files = glob.glob(\"DATA\\*.eml\")\n",
    "    emails_set = dict()\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            try:\n",
    "                text = msg.get_body(preferencelist=('plain')).get_content()\n",
    "            except:\n",
    "                text.encode('utf-32', 'surrogateescape').decode('utf-32') \n",
    "            new_text = flat_text(text)    \n",
    "            words_set = dict()\n",
    "            email_words = re.split(\" |\\n|\\t\", new_text)\n",
    "            for word in email_words:\n",
    "                try:\n",
    "                    words_set[word] += 1\n",
    "                except:\n",
    "                    words_set[word] = 1\n",
    "            emails_set[file.split(\"\\\\\")[1]] = words_set\n",
    "    return emails_set        \n",
    "\n",
    "def label_parser():\n",
    "    file = open(\"SPAMTrainn.label\", \"r\")\n",
    "    labels_set = dict()\n",
    "    if file.mode == 'r':\n",
    "        for line in file.readlines():\n",
    "            vec = line.split(\" \")\n",
    "            labels_set[vec[1].replace('\\n', '')] = vec[0]\n",
    "    return labels_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = email_parser()\n",
    "labels = label_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    p_spams = dict() #P(word|spam)\n",
    "    p_hams = dict() #P(word|ham)\n",
    "    p_spam = 0 #P(spam)\n",
    "    p_ham = 0  #P(ham)\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def divide(self, emails, labels):\n",
    "        spams = 0\n",
    "        hams = 0\n",
    "        words_spam = dict()\n",
    "        words_ham = dict()\n",
    "        words = dict()\n",
    "        n_spam = 0\n",
    "        n_ham = 0\n",
    "        for item in emails:\n",
    "            if(int(labels[item]) == 0):\n",
    "                spams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_spam[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_spam[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    n_spam  += emails[item][word]\n",
    "            else:\n",
    "                hams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_ham[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_ham[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    n_ham += emails[item][word]\n",
    "                    \n",
    "        return words, words_spam, words_ham, n_spam, n_ham, spams, hams\n",
    "    \n",
    "    def fit(self, emails, labels):\n",
    "        words, words_spam, words_ham, n_spam, n_ham, spams, hams = self.divide(emails, labels)\n",
    "        self.p_spam = (spams + self.k)/(spams + hams + 2*self.k) #P(spam)\n",
    "        self.p_ham = (hams + self.k)/(spams + hams + 2*self.k) #P(ham)\n",
    "        dict_size = len(words)\n",
    "        print(dict_size)\n",
    "        for item in words:\n",
    "            try:\n",
    "                self.p_spams[item] = (words_spam[item] + self.k)/(n_spam + (self.k*dict_size))\n",
    "            except:\n",
    "                self.p_spams[item] = (self.k)/(n_spam + (self.k*dict_size))\n",
    "            try:\n",
    "                self.p_hams[item] = (words_ham[item] + self.k)/(n_spam + (self.k*dict_size))\n",
    "            except:\n",
    "                self.p_hams[item] = (self.k)/(n_spam + (self.k*dict_size))\n",
    "\n",
    "    def predict(self, emails):\n",
    "        labels = list()\n",
    "        for item in emails:\n",
    "            print(emails[item])\n",
    "            p_bespam = 0\n",
    "            p_beham = 0\n",
    "            for word in emails[item]:\n",
    "                p_bespam += math.log(self.p_spams[word])\n",
    "                p_beham += math.log(self.p_hams[word])\n",
    "            print(p_bespam, \" \", p_beham)\n",
    "            print(self.p_spam, \" \", self.p_ham)            \n",
    "            p_bespam = p_bespam + self.p_spam\n",
    "            p_beham = p_beham + self.p_ham\n",
    "            labels.append(1 if p_bespam<p_beham else 0)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\n"
     ]
    }
   ],
   "source": [
    "nb.fit(emails, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email2_parser():\n",
    "    emails_set = dict()\n",
    "    with open(\"DATA\\TRAIN_00002.eml\", 'rb') as fp:\n",
    "        msg = BytesParser(policy=policy.default).parse(fp)\n",
    "        try:\n",
    "            text = msg.get_body(preferencelist=('plain')).get_content()\n",
    "        except:\n",
    "            text.encode('utf-32', 'surrogateescape').decode('utf-32') \n",
    "        new_text = flat_text(text)    \n",
    "        words_set = dict()\n",
    "        email_words = re.split(\" |\\n|\\t\", new_text)\n",
    "        for word in email_words:\n",
    "            try:\n",
    "                words_set[word] += 1\n",
    "            except:\n",
    "                words_set[word] = 1\n",
    "        emails_set[\"TRAIN_00001.eml\"] = words_set\n",
    "    return emails_set        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on': 2, 'sat': 1, '15': 1, 'may': 1, '10': 1, '': 147, '16': 1, '47': 1, '07': 1, 'merciadri': 1, 'luca': 1, 'wrote': 1, 'but': 5, 'will': 1, 'probably': 2, 'not': 6, 'work': 1, 'in': 3, 'you': 12, 'case': 1, 'as': 3, 'it': 8, 'was': 1, 'meant': 1, 'to': 12, 'combine': 1, 'two': 3, 'or': 4, 'more': 2, 'network': 3, 'ports': 1, 'from': 2, 'the': 11, 'same': 3, 'computer': 1, 'connected': 3, 'switch': 2, 'description': 1, 'says': 1, 'linux': 2, 'bonding': 2, 'driver': 1, 'provides': 1, 'a': 8, 'method': 1, 'for': 4, 'aggregating': 1, 'multiple': 1, 'interfaces': 1, 'into': 2, 'single': 1, 'logical': 1, 'bonded': 2, 'interface': 1, 'strictly': 1, 'speaking': 1, 'this': 6, 'is': 15, 'what': 2, 'i': 5, 'want': 2, 'now': 1, 'your': 4, 'interpretation': 1, 'seems': 1, 'be': 5, 'based': 1, 'definition': 1, 'of': 3, 'link': 1, 'aggregation': 1, 'which': 2, 'am': 2, 'really': 2, 'familiar': 1, 'with': 3, 'basically': 1, 'merge': 1, 'connections': 3, 'one': 4, 'at': 2, 'least': 1, 'divide': 1, 'and': 4, 'use': 7, 'them': 3, 'separately': 1, 'an': 2, 'easy': 1, 'way': 2, 'so': 1, 'rare': 1, 'situation': 1, 'e': 1, 'g': 1, 'might': 2, 'wandering': 1, 'some': 3, 'zone': 1, 'where': 2, 'can': 4, 'wifi': 3, 'sometimes': 1, 'unavailable': 1, 'say': 2, 'specific': 1, 'regions': 1, 'if': 3, 'manage': 1, 'another': 1, 'connection': 2, 'example': 2, 'that': 2, 'given': 1, 'by': 1, 'mobile': 1, 'phone': 1, 'smartphone': 2, 'via': 1, 'bluetooth': 1, 'then': 2, 'internet': 3, 'through': 1, 'other': 1, 'protocols': 1, 'should': 1, 'possible': 1, 'between': 1, 'these': 1, 'simultaneously': 1, 's': 4, 'range': 1, 'too': 3, 'small': 2, 'bandwidth': 1, 'compared': 1, 'okay': 1, 'realistic': 1, 'also': 1, 'share': 1, 'neighbour': 1, 'legally': 1, 'lot': 1, 'when': 1, 'he': 1, 'does': 1, 'need': 3, 'already': 1, 'ethernet': 1, 'both': 2, 'how': 1, 'suitable': 1, 'because': 1, 'works': 1, 'low': 1, 'level': 1, 'layer': 1, '2': 3, 'unless': 1, 'have': 2, 'links': 2, 'provider': 1, 'using': 2, 'technology': 2, 'like': 1, 'adsl': 1, 'afaiu': 1, 'bgp': 1, '1': 2, 't': 2, 'give': 1, 'any': 1, 'tips': 1, 'out': 1, 'my': 1, 'league': 1, 'good': 1, 'start': 1, 'whatever': 1, 'end': 1, 'up': 1, 'gnu': 1, 'preferably': 1, 'debian': 3, 'machine': 1, 'internal': 1, 'since': 1, 'consumer': 1, 'gateways': 1, 'don': 1, 'even': 1, 'than': 1, 'wan': 1, 'port': 1, 'http': 2, 'en': 1, 'wikipedia': 1, 'org': 2, 'wiki': 1, 'border': 1, 'gateway': 1, 'protocol': 1, 'could': 1, 'used': 1, 'custom': 1, 'firmware': 1, 'off': 1, 'topic': 1, 'regards': 1, 'andrei': 1, 'p': 1, 'there': 1, 'no': 1, 'cc': 1, 'me': 1, 'subscribed': 1, 'list': 1, 'offtopic': 2, 'discussions': 1, 'among': 1, 'users': 1, 'developers': 1, 'lists': 1, 'alioth': 1, 'mailman': 1, 'listinfo': 1, 'd': 1, 'community': 1}\n",
      "-1592.7898662280759   -1430.023809037955\n",
      "0.4166666666666667   0.5833333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(email2_parser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
