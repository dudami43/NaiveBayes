{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8bb990e061e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0memail\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_text(text):\n",
    "    new_text = \"\"\n",
    "    html_tag = False\n",
    "    for c in text:\n",
    "        if(c == \"<\"):\n",
    "            html_tag = True\n",
    "            continue\n",
    "        elif(c == \">\"):\n",
    "            html_tag = False\n",
    "            continue\n",
    "        if(html_tag == False):\n",
    "            if(c not in punctuation):\n",
    "                new_text += c\n",
    "            else:\n",
    "                new_text += \" \"\n",
    "    return new_text.lower()\n",
    "\n",
    "def email_parser():\n",
    "    files = glob.glob(\"DATA\\*.eml\")\n",
    "    emails_set = dict()\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as fp:\n",
    "            msg = BytesParser(policy=policy.default).parse(fp)\n",
    "            try:\n",
    "                text = msg.get_body(preferencelist=('plain')).get_content()\n",
    "            except:\n",
    "                text.encode('utf-32', 'surrogateescape').decode('utf-32') \n",
    "            new_text = flat_text(text)    \n",
    "            words_set = dict()\n",
    "            email_words = re.split(\" |\\n|\\t\", new_text)\n",
    "            for word in email_words:\n",
    "                try:\n",
    "                    words_set[word] += 1\n",
    "                except:\n",
    "                    words_set[word] = 1\n",
    "            emails_set[file.split(\"\\\\\")[1]] = words_set\n",
    "    return emails_set        \n",
    "\n",
    "def label_parser():\n",
    "    file = open(\"SPAMTrain.label\", \"r\")\n",
    "    labels_set = dict()\n",
    "    if file.mode == 'r':\n",
    "        for line in file.readlines():\n",
    "            vec = line.split(\" \")\n",
    "            labels_set[vec[1].replace('\\n', '')] = vec[0]\n",
    "    return labels_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = email_parser()\n",
    "labels = label_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x,y, train_size = 0.8):\n",
    "    perm = np.random.permutation(list(x.keys()))\n",
    "    dict_size = len(x)\n",
    "    x_train = dict()\n",
    "    y_train = dict()\n",
    "    x_test = dict()\n",
    "    y_test = dict()\n",
    "    i = 0\n",
    "    index = len(x)*train_size\n",
    "    for k in perm:\n",
    "        if (i < index):\n",
    "            x_train[k] = x[k] \n",
    "            y_train[k] = y[k]\n",
    "        else:\n",
    "            x_test[k] = x[k] \n",
    "            y_test[k] = y[k]\n",
    "        i += 1\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_train, label_train, email_test, label_test = train_test_split(emails, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    p_spams = dict() #P(word|spam)\n",
    "    p_hams = dict() #P(word|ham)\n",
    "    p_spam = 0 #P(spam)\n",
    "    p_ham = 0  #P(ham)\n",
    "    n_spam = 0 #Qtd total de palavras em spam\n",
    "    n_ham = 0 #Qtd total de palavras em ham\n",
    "    dict_size = 0 #Qtd de palavras distintas nos emails\n",
    "    \n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "        \n",
    "    def set_k(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def divide(self, emails, labels):\n",
    "        spams = 0\n",
    "        hams = 0\n",
    "        words_spam = dict()\n",
    "        words_ham = dict()\n",
    "        words = dict()\n",
    "      \n",
    "        for item in emails:\n",
    "            if(int(labels[item]) == 0):\n",
    "                spams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_spam[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_spam[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    self.n_spam  += emails[item][word]\n",
    "            else:\n",
    "                hams += 1\n",
    "                for word in emails[item]:\n",
    "                    try:\n",
    "                        words_ham[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words_ham[word] = emails[item][word]\n",
    "                    try:\n",
    "                        words[word] += emails[item][word]\n",
    "                    except:\n",
    "                        words[word] = emails[item][word]\n",
    "                    self.n_ham += emails[item][word]\n",
    "                    \n",
    "        return words, words_spam, words_ham, spams, hams\n",
    "    \n",
    "    def fit(self, emails, labels):\n",
    "        words, words_spam, words_ham, spams, hams = self.divide(emails, labels)\n",
    "        self.p_spam = (spams + self.k)/(spams + hams + 2*self.k) #P(spam)\n",
    "        self.p_ham = (hams + self.k)/(spams + hams + 2*self.k) #P(ham)\n",
    "        self.dict_size = len(words)\n",
    "        for item in words:\n",
    "            try:\n",
    "                self.p_spams[item] = (words_spam[item] + self.k)/(self.n_spam + (self.k*self.dict_size))\n",
    "            except:\n",
    "                self.p_spams[item] = (self.k)/(self.n_spam + (self.k*self.dict_size))\n",
    "            try:\n",
    "                self.p_hams[item] = (words_ham[item] + self.k)/(self.n_ham + (self.k*self.dict_size))\n",
    "            except:\n",
    "                self.p_hams[item] = (self.k)/(self.n_ham + (self.k*self.dict_size))\n",
    "\n",
    "    def predict(self, emails):\n",
    "        labels = list()\n",
    "        for item in emails:\n",
    "            p_bespam = math.log(self.p_spam)\n",
    "            p_beham = math.log(self.p_ham)\n",
    "            for word in emails[item]:\n",
    "                try:\n",
    "                    p_bespam += math.log(self.p_spams[word])\n",
    "                except:\n",
    "                    p_bespam += math.log((self.k)/(self.n_spam + (self.k*self.dict_size)))\n",
    "                try:\n",
    "                    p_beham += math.log(self.p_hams[word]) \n",
    "                except:\n",
    "                    p_beham += math.log((self.k)/(self.n_ham + (self.k*self.dict_size)))\n",
    "            labels.append(1 if p_bespam<p_beham else 0)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, labels_val):\n",
    "    num = 0\n",
    "    total = 0\n",
    "    for i in labels_val:\n",
    "        if(prediction[total] == int(labels_val[i])):\n",
    "            num += 1\n",
    "        total += 1\n",
    "    return num/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid_search_cv:\n",
    "    \n",
    "    x = dict()\n",
    "    y = dict()\n",
    "    def __init__(self, clf, params, cv = 10):\n",
    "        self.clf = clf\n",
    "        self.params = params\n",
    "        self.cv = cv\n",
    "    def kfold(self, k, param):\n",
    "        size_part = len(self.x)//k\n",
    "        perm = np.random.permutation(list(self.x.keys()))\n",
    "        self.clf.set_k(param)\n",
    "        acc = 0\n",
    "        for i in range(k):\n",
    "            val_part_keys = perm[size_part*i:(size_part*(i+1))-1] \n",
    "            train_x = dict()\n",
    "            train_y = dict()\n",
    "            val_x = dict()\n",
    "            val_y = dict()\n",
    "            for key in self.x:\n",
    "                if(key in val_part_keys):\n",
    "                    val_x[key] = self.x[key]\n",
    "                    val_y[key] = self.y[key]\n",
    "                else:\n",
    "                    train_x[key] = self.x[key]\n",
    "                    train_y[key] = self.y[key]\n",
    "            self.clf.fit(train_x, train_y)\n",
    "            prediction = self.clf.predict(val_x)\n",
    "            acc += accuracy(prediction, val_y)\n",
    "        return acc/k\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        best_acc = 0\n",
    "        for i in self.params:\n",
    "            acc = self.kfold(self.cv, i)\n",
    "            print(\"k: \", i, \" Acurácia: \", acc)\n",
    "            if(acc > best_acc):\n",
    "                best_acc = acc\n",
    "                best_param = i\n",
    "        print(\"K escolhido para a suavização aditiva: \", best_param)\n",
    "        self.clf.set_k(best_param)\n",
    "        self.clf.fit(x,y) #treinar o classificador de novo com o conjunto todo\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.arange(0.1,1,0.1)\n",
    "gs = grid_search_cv(nb, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  0.1  Acurácia:  0.9799999999999999\n",
      "0.9799999999999999\n",
      "k:  0.2  Acurácia:  0.9753623188405797\n",
      "0.9799999999999999\n",
      "k:  0.30000000000000004  Acurácia:  0.9736231884057972\n",
      "0.9799999999999999\n",
      "k:  0.4  Acurácia:  0.9707246376811595\n",
      "0.9799999999999999\n",
      "k:  0.5  Acurácia:  0.9678260869565218\n",
      "0.9799999999999999\n",
      "k:  0.6  Acurácia:  0.9672463768115941\n",
      "0.9799999999999999\n",
      "k:  0.7000000000000001  Acurácia:  0.9669565217391304\n",
      "0.9799999999999999\n",
      "k:  0.8  Acurácia:  0.9657971014492753\n",
      "0.9799999999999999\n",
      "k:  0.9  Acurácia:  0.9637681159420289\n",
      "0.9799999999999999\n"
     ]
    }
   ],
   "source": [
    "gs.fit(email_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gs.clf.predict(email_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9618497109826589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(prediction, labels):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for i in labels:\n",
    "        if(prediction[total] == 1 and int(labels[i]) == 1):\n",
    "            tp += 1\n",
    "        elif(prediction[total] == 1 and int(labels[i]) == 0):\n",
    "            fp += 1\n",
    "        elif(prediction[total] == 0 and int(labels[i]) == 0):\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    array = [[tp, fp],[fn, tn]]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(prediction, label_test)\n",
    "df_cm = pd.DataFrame(array, index = [\"positive\", \"negative\"],\n",
    "                  columns = [\"postive\", \"negative\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
